When addressing a point from the reviews, please remove it from this todo file,
and commit in the same patch.

----------------------- REVIEW 2 ---------------------

The paper is on the whole well organized, with the exception of Section 2.1. The
latter lacks examples for the different analyses which are presented. It is also
hard to understand from this section how the new algorithm relates to the
different passes, at which stage it is inserted, or which stage it replaces (see
the detailed comments). As the paper is not very long (7 pages), I strongly
suggest that the authors take the time to enhance this part for the sake of
clarity.

The authors show that the detected SCoPs are largest than with previous
techniques. It would be interesting to know the impact on the overall
compilation time (including polyhedral code generation) wrt the efficiency of
the code generated, to estimate whether the additional SCoPs or SCoP parts lead
to execution time gains and don't affect too much the compilation time. On the
Polybench, the authors report a compilation slowdown for SCoP detection which
leads to more interesting SCoPs, but there is no quantified results. If the
authors could give these results in the final version of the paper, it would be
very interesting.


Detailed comments:
==================

Check overfull hboxes.

Section 2:
----------

It's not really clear from the introduction of Section 2 what is presented in
Section 2.1. Does it describe the succession of passes in both Graphite and
Polly? Is it a collection of passes some of which are available in these
compilers? In this case, explain which ones are available in each compiler, and
in which order they are scheduled (pictures may be helpful). Are all these
phases also available in your new implementation? Only some of them?

A small example would very helpful for the various representations: CFG, SESE,
natural loops, SSA (especially for loop phi nodes, and loop close phi nodes),
scev (give an example of scev), which may not be all familiar to all readers.

Explain how pointer analyses, alias analyses, data reference analysis and
delinearization analysis interfere with SCoPs detection. in particular, are
these analyses those already available in gcc, or are they specific to
polyhedral analyses?

2.4: I was a bit surprised by this section, because you demonstrate that it may
not be interesting to detect maximal SCoPs, but at the same time you advocate
that your algorithm can detect larger SCoPs that other algorithms. So, what is
the right criterion for the extent of a SCoP? And how does your new algorithm
meet this criterion?

Section 3:
----------

Figure 2:

Add line numbers so that you can refer to them in Section 3.1.

Section 3.3:

Section 5:

2- It seems to me that in most cases the sets of natural loops which have good
chances of being identified as SCoPs are well-formed loops in the program AST,
not separated by any weird control flow due to gotos, returns, ... Wouldn't it
be more effective to perform the analysis on an even higher-level
representation, closer to the AST (I have in mind for instance PIPS's HCFG,
which retains the AST whenever possible and switches to a local CFG otherwise)?
This of course may also depend on how other analyses (such as pointer analyses
and alias analyses) results are available...


----------------------- REVIEW 3 ---------------------

the document lacks
information about the original design and implementation choices behind GCC's
current SCoP detection mechanism, which would be insightful (since the authors
have a deep knowledge about its development).

-- Introduction --

I understand that C++ exceptions are being used as an example of structural
decomposition happening in the compiler front end, but the relation to SCoPs is
not always evident for the reader.

Some argument on why conservative SCoP detection as in [2] results in large
overheads may strengthen the motivation for the current work. In particular, it
is not clear to me why it would make the SCoP detection itself more expensive as
it relaxes and simplifies SCoP constraints. This is obviously different for
optimization because SCoPs would be larger, but this is another question.


-- Comparative Analysis ... --

The first subsection gives a very nice brief overview of the pertinent data
structures maintained by the compiler during the optimization process.  However,
given its length, the reader may wonder as to why all these structures are
relevant for the SCoP extraction.  Starting with a short argument on the utility
of the natural loops representation may help.  Also, analyses that actually
generate a representation are mixed with others. The authors may consider to
separate them.

-- A New Faster SCoP Detection --

The algorithm is well described except for the following points.

- More generally, I assume that all CFG or natural loop tree traversal functions
  (a) return NULL if a node is not found and (b) include a recursion bound
  condition when their arguments are NULL, but this is not stated in the paper;
  as this information is not related to the functioning of the algorithms
  themselves, it may be included in, e.g. a figure caption;

If all my assumptions listed above are correct, the algorithm looks fully
operational.


-- Experimental Results --

For PolyBench results in Fig.5, using test case names would be preferable to
assigning integer numbers with unclear mapping.  It may be also interesting to
report the outcome of the SCoP detection along with the speedup/slowdown for
this benchmark, e.g. did the case with ~0.33 speedup resulted in three times
larger SCoPs?

Contrary to the last paragraph, Fig.6 does not immediately report detection
speedup on the GCC source files, but allows to analyze the ratio between the
percentage of the compilation time spent in SCoP detection compared to overall
compilation time.  Given that the overall compilation time decreased as well,
namely due to analyzing less SCoPs that were detected, assessing speedup may be
challenging.

Finally, the authors report that the new SCoP detection algorithm does not
consider single-loop SCoPs in the results, but do not mention whether it was a
deliberate choice or a side effect of the algorithm and what may be the negative
repercussions of it (or positive with respect to detection speedup).

(I guess it is, but is the phase ordering and phases the same when comparing GCC
6.0's SCoP detection against the old one ? My question is just in case it was
not possible for both SCoP detection mechanisms to coexist in GCC 6.0
development version.)

-- Conclusion --

After the motivating introduction, I wonder will, in the end, the polyhedral
optimization be enabled by default in GCC and at which levels?

Similarly, the conclusion leaves profile-guided optimization for the future work
while the abstract makes allusion to “-fprofile-use” flag enabling it.


----------------------- REVIEW 4 ---------------------

The paper’s criticism of quadratic nature of Polly’s SESE regions detection is
weak and not based on practical inputs. It is true that use of Iterated
Dominance Frontier (IDF) can lead to a quadratic behavior on loops, but, those
variety of codes are based on pathological constructs
[Cytron—Ferrante-TOPLAS-95, Figures 1 and 2] which may not occur in practice. It
is likely that Polly does not suffer from this limitation on practical inputs.

The paper’s reliance of SCC components and depths of loops is quite similar to
the approach of Sreedhar-Gao-Lee-TOPLAS-96 who use an additional annotation on
their dominance trees (which they call as “DJ graphs”).  A comparison of the
paper's approach with the above work would be appropriate.

----------------------- REVIEW 6 ---------------------

The technical contribution lies in a SCOP detection engine which takes advantage
of the natural loop detection and scev passes in gcc. The proposed approach
makes the choice of not always looking for the largest enclosing scop in order
to save compile time. This makes perfectly sense when SCOP detection represents
a significant part of the compiler run-time, however, given the results provided
in section 4, it is not clear how relevant this design choice is.

Here are a few remarks:

 - The claim of subsection 2.4 should however be a bit nuanced, or backed with
   quantitative evidence. In that example, the « if » guard expression may bring
   valuable context information on the domain parameters, which in turn can have
   a significant impact on the efficiency of the generated code.

 - Since the technique is based on a tree-based representation for loop, how
   different the technique is from those used in source-level polyhedral tools
   such as Pet, Clan, PolyRose, etc.

 - I believe the authors should provide a little bit more background (and an
   example) on the specific SSA representation used in this work and its
   relation with the scev pass (this may be done at the expense of the reminder
   on CFG, dominance tree, which are normally well understood).

 - The typesetting for algorithms (figure 2,3,4) make them difficult to follow
   (and ugly!), please use one of the numerous latex algorithm packages to
   improve the rendering. Also, I found the description/explanation of the
   algorithms a bit redundant with the algorithm themselves, and would have
   preferred to have examples instead.

 - Although I understand that the goal of the paper is not to compare against
   polly/llvm, I was a bit frustrated after reading section 4.1. I would have
   appreciated that authors discuss a bit more in details the difference (and
   impact of these difference) between polly and the proposed
   approach. Similarly, the authors should explain with more details how SCOP
   extraction was performed in earlier version of graphite, and why it could not
   benefit from scev (this is a bit unclear).

 - The performance results are a bit disappointing, in the sense that the
   initial SCOP detection runtime did not seem to have significant overhead (<2%
   of compile time). This somewhat makes the performance improvement less
   relevant.  It maybe that such a performance gain is a big deal in practice,
   but this should be explained/motivated.


----------------------- REVIEW 7 ---------------------
The acronym SCoP si incorrect, and should be replaced by either ACLs (Affine
Control Loops) or PWAC (Parts With Affine Control, rhymes with quack :-)

Seb: to confuse people even more, I suggest that we change the title of the
paper to: "ACL -- Austin City Limits: A Fast Tour of an Industrial Compiler City"
