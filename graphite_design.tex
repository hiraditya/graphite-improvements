\documentclass{sigplanconf}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amssymb}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{Impact'16}{January 18--20, 2016, Prague, Cz}
\copyrightyear{2016} 
\doi{nnnnnnn.nnnnnnn}

\title{A faster SCoP detection}
\authorinfo{Aditya Kumar, Sebastian Pop}
\authorinfo{Samsung Austin R\&D Center}

\maketitle

\begin{abstract}
  For the past few years graphite framework, which brought polyhedral optimizations
  to gcc, was largely unmaintained. We made importatnt designed changes and fixed bugs accumulated over
  the past. The transition from cloog to isl left dead code in multiple places, and made some optimizations
  redundant. We cleaned up that code, so graphite codebase became smaller after recent changes.
  We enabled graphite to detect wider range of loops which it can optimize and discard
  difficult-to-optimize loops in a much faster way. We have also brought demand driven optimization
  into the graphite framework, since we want it to spend extra time in loops which matters,
  in the presence of profile information.
  Demand driven optimization is new approach to optimization: Moving from problem to solution.
\end{abstract}


\section{Introduction}
\subsection{What is a SCoP?}

\subsection{Why we need to detect scops for translation in polyhedral model?}

\subsection{Existing implementations: graphite, polly}
short introduce region trees

\subsection{Contributions of this paper}
\begin{enumerate}
  \item Algorithm for scop detection.
  \item Comparative analysis of llvm-polly, earlier graphite, current algorithm.
  \item SCoPs detected by llvm-poly vs. Graphite.
  \item Experimental results on compile time improvements.
\end{enumerate}



\section{Related work}

\subsection{Current algorithm for scop detection in Graphite}

Describe the current status of Graphite scop detection: limitations, and compilation time.

Part of limitation, the functionality limit-scop was added as an intermediate
step to discard the loops which graphite could not handle. Removing limit-scop
required handling of different cases of loops and surrounding code.  The scop is
now larger so most test cases required 'number of scops detected' to be
fixed. By increasing the size of scop we can now optimize loops which are
'siblings' of each other. This could enable loop fusion on a number of loops.

\subsection{Polly scop detection: a region based SCoP detection}

\subsection{Maximal SCoPs and why they might not be very useful.}
A Maximal SCoP is the larges such SCoP which cannot be extended further. This concept is used
in LLVM 
%\cite{Tobi}
and in previous graphite implementation.
%\cite{Graphite}. 
Since the main focus of
polyhedral optimizations is the loops and code surrounding it, finding a maximal SCoP might introduce branches
which are not related to loops at all. e.g.,

\begin{comment}
Scop
Cond
|
|--True Region
|
|--False Region
|       | Loop1
|       |
\end{comment}

In this example The cond and True regions just add extra code to the polyhedral analysis and transformations if there
are no loops in it. Even if there are loops in True region they better be analyzed separately because
execution of Loop1 and True Region are mutually exclusive.
Having just the Loop1 as SCoP would prove more beneficial in terms of optimizations and overall compile time.



\section{A new faster scop detection to select relevant loop nests}
The scope of the polyhedral program analysis and manipulation is a sequence of loop
nests with constant strides and affine bounds. It includes non-perfectly nested loops
and conditionals with boolean expressions of affine inequalities.
The maximal Single-Entry Single-Exit (SESE) region of the Control Flow Graph
(CFG) that satisfies those constraints is called a Static Control Part (SCoP). \cite{Girbal, Bondhugula, trifunovic}

Current algorithm for SCoP detection in graphite was based on dominator tree where a tree (CFG) traversal is required
for analyzing an SESE. The tree traversal is linear in the number of basic blocks and SCoP detection is linear in
number of instructions. This is reasonably fast but it utilizes a generic infrastructure of SESE. With regards to
polyhedral optimization we are only interested in subtrees with loops. So it makes more sense to utilize higher level
semantics of CFG e.g., loop tree. Since higher level abstractions contain more statments, discarding them early
makes algorithm converge faster.

The new algorithm is geared towards tree traversal on loop structure. The algorithm is linear in number of loops
which is much faster than the previous algorithm. The algorithm is based on a very simple structural property of loop
tree.

LoopTree = LoopNest
LoopNest = LoopTree; nested loop

Briefly, we start the traversal at a loop-nest and analyze it recursively for validity. Once a valid loop is
found we find a valid adjacent loop. If an adjacent loop is found then we merge both loop nests
other wise we form a SCoP and resume the algorithm from the adjacent loop nest. The data structure to represent an SESE
is an ordered pair of edges (entry, exit). Choosing a simple data structure allows us to extend a SCoP in both the
directions. With this approach, the number of instructions to be analyzed for validity reduces to a minimal set.
We start by analyzing those statements which are inside a loop, because validity of those statements is
necessary for the validity of loop. The statements outside the loop nest can be just excluded from the
SESE if they are not valid.

In the graphite framework we do not include statements outside before the first and after the last loop in an SESE.
So in that sense, SCoP detected by this function may not be maximal.

GIMPLE statements belonging to the SCoP should not contain calls to functions with
side effects (pure and const function calls are allowed) and the only memory references
that are allowed are accesses through arrays with affine subscript functions.

To make the scop detection simpler we canonicalize the loops into a closed SSA form.
The previous graphite framework detected scop by analyzing an SESE. That approach resulted in a highly recursive structure
with redundancies at several places and hence, increase in compile time. In the new framework, we try to discard irrelevant
regions as fast as we can. Essentially,
\begin{enumerate}
\item Discard functions with less than two loops: Since we are mostly intersted in optimizing loop nests
or loop which has at least one sibling.
\item Start the scop detection from a CFG node which begins from a loop header.
\item Break the SCoP at a point where we find a statement which cannot be represented by graphite.
\item 
\end{enumerate}


\subsection{merging sub-scops to form larger scops}
We compose larger SCoPs by merging smaller ones at the same loop depth. After combining the sub-scops
the newly formed scop has to be reanalyzed for all the validity requirements:
\begin{enumerate}
  \item The entry basic block should have only one predecessor and the exit basic block should have only one
    successsor.
  \item The entry should dominate the exit.
  \item The exit should post-dominate the entry.
  \item Writes to outside of SCoP.
  \item The scalar evolution of all the operands in the new region should be affine.

    \begin{enumerate}
      \item The statement should not have any side effects.
      \item Only label, pure call, assignments and comparison operations on integers are allowed.
    \end{enumerate}
\end{enumerate}

Even if we have analyzed the statements in a sub-scop we need to redo the whole thing because the scalar evolution
of the references change with the scope of the program under analysis.


\section{Experimental Results}

On Polybench:
on graphite original scop detection, 189 scops, max loops/scop 8, min loops/scop 1: 109 scops with 1 loop/scop, 316 loops in scops, 1.67 loops/scop
without 1loop/scop, 80 scops contain 207 loops -> 2.59 loops/scop.

on the new scop detection: 34 scops, max loops/scop 17, min loops/scop 2: 7 scops with 2 loops/scop, 207 loops in scops, 6.09 loops/scop

=> no regressions new/original scop detection, we only discover larger scops (316 - 207 = 109)
=> removing limit-scops discovers larger scops: 2.59 -> 6.09

on polly: Number of scops detected: 30, max loops/scop 11, min loops/scop 2: 3 scops with 2 loops/scop, 155 loops in scops, 5.17 loops/scop


compile time:
- graphite old, new
- polly: region pass, scop detection

number of scops detected per benchmark


\section{Conclusion and Future Work}


\bibliographystyle{abbrv}
{\small
\bibliography{Bibliography}
}
\end{document}
